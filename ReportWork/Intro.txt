Introduction / Background / Motivation:
o (5 points) What did you try to do? What problem did you try to solve? Articulate your objectives
using absolutely no jargon.

The original plan for our project was to investigate how various hyperparameters behave and influence the training, metrics,
space contraints, as well as other intriguing characteristics when training a model. We started with the Open Catalyst Project (OCP),
which is a large multi-year effort that is investigating chemical compositions and interations to try and help find new combinations
to address the effects of climate change. After a significant effort in getting the code environment to work, we found that the sheer size
of the data and models required multiple GPUs worth of vRAM and thousands of GPU hours to train a single model, with a single GTX 4090 taking
approximately 11 hours to complete one epoch of training. Due to these computational requirements, our original plan and scope was out of reach. 
With this finding, we decided to pivot the focus to reduction in model complexity using pruning such that we could explore a topic within the timeline.
Pruning a neural network involves reducing model complexity by removing parameters, connections, or layers of the network. In our work we pruned parameters.
To investigate pruning, we first attempted to lower the computational requirements by pruning the OCP models. This proved insufficient as sparse operations
were not supported, meaning the pruning only lowered model complexity but not computational requirements. Thus, we chose to investigate model degradation
due to pruning focusing on the VGG16 architecture trained on the CIFAR100 dataset. To investigate the model degradation we attempted to use visualization
techniques of class image generation, saliency maps, and GradCAM investigated in earlier work. By applying these visualization techniques to pruned models
we hoped to expand quantitative measures of model degradation with qualitative descriptions the effect of pruning on image classifiers.


References: 
https://towardsdatascience.com/how-to-prune-neural-networks-with-pytorch-ebef60316b91
https://olegpolivin.medium.com/experiments-in-neural-network-pruning-in-pytorch-c18d5b771d6d
https://nni.readthedocs.io/en/stable/compression/pruner.html



o (5 points) How is it done today, and what are the limits of current practice?
As mentioned previously, pruning algorithms can modify various aspects of the neural network to reduce complexity and can range from
parameter reduction, structure complexity reduction, and lowering numerical precision within a network [1]. Current approaches attempt to train
a large model with greater than adequate accuracy, prune the model to a desired size, and retrain the model to fine tune the weights post-pruning.
Recent attempts have used joint-training of the parent model with the smaller child models using a shared weight matrix in order to train an un-pruned
large model that can be pruned and produce efficient networks without the need for retraining [2]. Others have attempted to use quantization to convert
a full-precision model to a lower-precision model while mainatining accuracy close to the original model [3]. Other work attempts to generate different
methods and criterion to optimize the pruned model effectiveness measured through quantitative means and prediction visualization [4-6].
Efforts to visualize pruning methods in the past have focused on visualizing feature representations, the pruning process, and describing summary 
statistics related to the pruning [7-8]. While this leads to efficient pruning algorithms in terms of model performance post-pruning, they provide
limited delivery of interpretability and understandability for how the model degrades or why the performance of the pruned model is comparable to the
parent model. 

References:
[1] https://nni.readthedocs.io/en/stable/compression/pruner.html
[2] https://arxiv.org/pdf/1908.09791.pdf
[3] https://arxiv.org/pdf/1702.03044.pdf
[4] https://www.sciencedirect.com/science/article/pii/S0031320321000868
[5] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8914711/
[6] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8950981/
[7] https://arxiv.org/pdf/2205.15731.pdf
[8] https://arxiv.org/pdf/2009.09940.pdf



o (5 points) Who cares? If you are successful, what difference will it make?
Recent advances of deep learning models have shown numerous models reaching into trillions of parameters such as GPT-4 [1]. As mentioned in the introduction,
the OCP models also had a significant number of parameters, leading to the requirement of thousands of GPU hours of computation to train a single model [2].
This level of compute presents novel challenges for personal, organizational, and societal use of AI to solve problems and advance innovation. Public perception of
AI models like is important to driving engagement, and some reporting of GPT-4 refers to the model as a "bloated, pointles mess" [3]. Training these large models can
also contribute to climate change, with a single large transformer model being estimated to emit approximately 6 cars worth of CO2 [4]. Inference using machine learning
models also represents a computational cost and considerable effort has been made to investigate efficient inference methods and energy costs [5, 6]. 
Finally, reliance on large models with large compute requirements as the state of the art presents a barrier to entry for prospective researchers and is bottleneck to 
investigation as a single training epoch can require many hours of GPU time to complete which represents a large time and monetary cost to training. 
This project sought to contribute to providing tools that would enable more efficient models to be produced with fewer iterations, while maitaining interpretability.


References:
[1] https://openai.com/research/gpt-4
[2] https://arxiv.org/pdf/2206.08917.pdf
[3] https://www.theatlantic.com/technology/archive/2023/03/openai-gpt-4-parameters-power-debate/673290/
[4] https://arxiv.org/pdf/1906.02243.pdf
[5] https://www.sciencedirect.com/science/article/pii/S2210537923000124
[6] https://dl.acm.org/doi/pdf/10.1145/3472883.3486993



o (5 points) What data did you use? Provide details about your data, specifically choose the most
important aspects of your data mentioned here: Datasheets for Datasets
(https://arxiv.org/abs/1803.09010). Note that you do not have to choose all of them, just the most
relevant

For the initial investigation into the OCP models we made use of the OC22 s2ef and is2rs datasets and the gemnet-oc model [1]. Both datasets proved to be
difficult to compute despite the is2rs datset being significantly smaller than the s2ef dataset due to requiring a very low batch size to satisfy memory constraints. 
When moving away from the OCP dataset we chose to use the CIFAR-100 dataset [2]. We chose CIFAR-100 because it is a challenging image dataset, due to many categories with
minimal examples and low resolution. We also chose CIFAR-100 because the low resolution of the images would provide an easier visual for localization of pruning effects.
To focus on the visualization of the effects of pruning we used a pre-trained VGG16 model with baseline 74% Top-1 Accuracy and 15.3M parameters [3]. We chose to use VGG16 
as it has very high accuracy and a large number of parameters that could be pruned.

References:
[1] https://github.com/Open-Catalyst-Project/ocp/blob/main/DATASET.md#structure-to-total-energy-and-forces-s2ef-total-task
[2] https://www.cs.toronto.edu/~kriz/cifar.html
[3] https://github.com/chenyaofo/pytorch-cifar-models

##This will need more with some more specifics


